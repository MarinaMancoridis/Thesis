{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4791e514",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook explores how false publications in science can emerge as the product of a multi-generational simulation of science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "abc4b4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.stats import beta, binom, entropy\n",
    "import random\n",
    "import json\n",
    "import copy\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "# my modules\n",
    "import scientist\n",
    "import evaluation\n",
    "import helper\n",
    "import settings\n",
    "import publisher\n",
    "\n",
    "# global variables\n",
    "num_bins = 4\n",
    "num_draws = 10\n",
    "num_participants = 10\n",
    "num_generations = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25ed802e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of bins\n",
    "bins_to_probs = {}\n",
    "for i in range(0, num_bins):\n",
    "    bins_to_probs[i] = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02c3dc4",
   "metadata": {},
   "source": [
    "## Initialize participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dabb7aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_participants(setting, alpha_value):\n",
    "    participants = []\n",
    "\n",
    "    for i in range (0, num_participants):\n",
    "        if setting == \"rate\":\n",
    "            report_set = settings.ReportingSetting(\"rate\")\n",
    "        elif setting == \"data\":\n",
    "            report_set = settings.ReportingSetting(\"data\")\n",
    "        elif setting == \"subset\":\n",
    "            report_set = settings.ReportingSetting(\"subset\")\n",
    "\n",
    "        # make participant\n",
    "        participant = scientist.Participant(alpha=alpha_value, reporting_setting=report_set)\n",
    "                        \n",
    "        participants.append(participant)\n",
    "\n",
    "    return(participants)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39911151",
   "metadata": {},
   "source": [
    "## Run an experiment\n",
    "\n",
    "The multi-generational experiment is run, given reporting setting and exaggeration values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e60e867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(setting, alpha_value, rel_pl_data_val, rel_pl_surprise_val, rel_pl_bias_val):\n",
    "    # each experiment starts with a blank cannon (starts with 1-1 prior)\n",
    "    scientific_record = {}\n",
    "    for bin_num in range(0, num_bins):\n",
    "        scientific_record[bin_num] = {} \n",
    "        scientific_record[bin_num][0] = 1\n",
    "        scientific_record[bin_num][1] = 1\n",
    "    \n",
    "    for generation in range(0, num_generations):\n",
    "#         print(f\"\\n* Generation {generation}...\")\n",
    "#         helper.print_record(scientific_record, num_bins)\n",
    "#         print(f\"   Arm score: {evaluation.arm_parameter_score(scientific_record, bins_to_probs)}\")\n",
    "#         print(f\"   Entropy score: {evaluation.total_entropy_score(scientific_record, bins_to_probs)}\")\n",
    "        \n",
    "        # each generation gets an entirely new set of participants\n",
    "        participants = make_participants(setting, alpha_value)\n",
    "\n",
    "        # scientists explore and submit reports\n",
    "        for participant in participants:\n",
    "            # sample\n",
    "            for i in range(0, num_draws):\n",
    "                bin_number, value = participant.sample(scientific_record, num_bins, bins_to_probs)\n",
    "                \n",
    "#                 print(f\"   sample from bin {bin_number}: {value}\")\n",
    "\n",
    "            # choose the bin\n",
    "            bin_choice = participant.choose_bin(scientific_record, num_bins, num_draws)\n",
    "#             print(f\"   chose bin {bin_choice}\")\n",
    "\n",
    "            # make a report\n",
    "            participant.report(num_bins, num_draws)\n",
    "            \n",
    "        # the peer review board selects reports for publication and returns the updated scientific record\n",
    "        scientific_record = publisher.peer_review(participants, scientific_record, rel_pl_data_val, rel_pl_surprise_val, rel_pl_bias_val)\n",
    "        \n",
    "#     print(\"\\n\\n* FINAL RESULTS\")\n",
    "#     # final metric of how well scientists play the multi-armed bandit game\n",
    "#     print(evaluation.arm_parameter_score(scientific_record, bins_to_probs))\n",
    "\n",
    "#     # final metric of how well scientists reduce the entropy of the scientific record\n",
    "#     print(evaluation.total_entropy_score(scientific_record, bins_to_probs))\n",
    "    \n",
    "    return(evaluation.arm_parameter_score(scientific_record, bins_to_probs), evaluation.total_entropy_score(scientific_record, bins_to_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "43ce5884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15625, 0.07998783325514161)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_experiment(\"data\", 0, 0, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3641b67",
   "metadata": {},
   "source": [
    "## Searching over the space of publishing policies\n",
    "\n",
    "Search across relative weights of how much data is associated with a report, how surprising the report is, and publication bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "174f3e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale over amount of supporting data\n",
    "rel_pl_data = np.linspace(0, 10, 21)\n",
    "\n",
    "# scale over how surprising the data is\n",
    "rel_pl_surprise = np.linspace(0, 10, 21)\n",
    "\n",
    "# rate of bump for publication bias (0.01 = 1% publication bias)\n",
    "rel_pl_bias = np.linspace(0, 1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a4f679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examining value: 0.0\n",
      "examining value: 0.5263157894736842\n",
      "examining value: 1.0526315789473684\n",
      "examining value: 1.5789473684210527\n",
      "examining value: 2.1052631578947367\n",
      "examining value: 2.631578947368421\n",
      "examining value: 3.1578947368421053\n",
      "examining value: 3.6842105263157894\n",
      "examining value: 4.2105263157894735\n",
      "examining value: 4.7368421052631575\n",
      "examining value: 5.263157894736842\n",
      "examining value: 5.789473684210526\n",
      "examining value: 6.315789473684211\n",
      "examining value: 6.842105263157895\n",
      "examining value: 7.368421052631579\n",
      "examining value: 7.894736842105263\n",
      "examining value: 8.421052631578947\n"
     ]
    }
   ],
   "source": [
    "publishing_policies_space = {}\n",
    "exp_no = 0\n",
    "\n",
    "for rel_pl_data_val in rel_pl_data:\n",
    "    print(f\"examining value: {rel_pl_data_val}\")\n",
    "    for rel_pl_surprise_val in rel_pl_surprise:\n",
    "        for rel_pl_bias_val in rel_pl_bias:\n",
    "            total_arm_score = 0\n",
    "            total_entropy_score = 0\n",
    "           \n",
    "            for i in range(0, 10):\n",
    "                arm_score, entropy_score = run_experiment(\"data\", 0, rel_pl_data_val, rel_pl_surprise_val, rel_pl_bias_val)\n",
    "                total_arm_score += arm_score\n",
    "                total_entropy_score += entropy_score\n",
    "            \n",
    "            key = (rel_pl_data_val, rel_pl_surprise_val, rel_pl_bias_val)\n",
    "            publishing_policies_space[key] = [total_arm_score / 10, total_entropy_score / 10] # average over 10 runs of each combination\n",
    "            exp_no += 1\n",
    "            \n",
    "# save the results\n",
    "pickle.dump(\n",
    "    publishing_policies_space,\n",
    "    open(\"/Users/marinamancoridis/Thesis/Thesis_Simulations/publishing_policies.p\", \"wb\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a103a09c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7b3bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb6c0bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
