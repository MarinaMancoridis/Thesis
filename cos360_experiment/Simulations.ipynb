{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ee15324",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook explores how different simulation settings affect the frequency of false results being published in a pseudo-scientific setting. It demonstrates that sevearal hypothesized effects emerged in single-generation simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d98c1ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from scipy.stats import beta, binom\n",
    "import random\n",
    "\n",
    "# simulation-wide global variables\n",
    "num_bins = 3\n",
    "num_draws = 10\n",
    "num_participants = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8595c6c",
   "metadata": {},
   "source": [
    "###  Reporting Settings\n",
    "A participant is in one of three settings for how they are allowed to report their data\n",
    "1. **Rate**: Pick a single bin and report the survival rate of its pill contents.\n",
    "2. **Data**: Pick a single bin and report the total number of rats that died and rats that stayed alive\n",
    "3. **Subset**: Pick a single bin and choose a set of data to publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5719f0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportingSetting:\n",
    "    def __init__(self, name):\n",
    "        if name not in {\"rate\", \"data\", \"subset\"}:\n",
    "            raise ValueError(\"Improper setting name\")\n",
    "        self.name = name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9668707f",
   "metadata": {},
   "source": [
    "### Participants\n",
    "A participant implements a given strategy for how they gather data and a strategy for how they report data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d2d9a5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Participant:\n",
    "    def __init__(self, strategy_gather, strategy_bin, strategy_report, reporting_setting):\n",
    "        self.strategy_gather = strategy_gather                               # strategy to collect data\n",
    "        self.strategy_bin = strategy_bin                                     # strategy to select bin to report\n",
    "        self.strategy_report = strategy_report                               # strategy to report data in the chosen bin\n",
    "        self.reporting_setting = reporting_setting                           # type of report a participant can make\n",
    "        self.bin_sample_order = []                                           # order of bins sampled\n",
    "        self.values_sampled = []                                             # values received across draws\n",
    "        self.bin_choice = -1                                                 # the bin chosen to be reported\n",
    "        reported_results = None                                              # the results reported\n",
    "        \n",
    "    def sample(self):\n",
    "        sample_number = len(self.bin_sample_order)\n",
    "        bin_number, value = self.strategy_gather.draw(len(self.values_sampled), self.bin_sample_order, self.values_sampled)\n",
    "        self.bin_sample_order.append(bin_number)\n",
    "        self.values_sampled.append(value)\n",
    "        \n",
    "    def choose_bin(self, bin_sample_order, values_sampled):\n",
    "        self.bin_choice = self.strategy_bin.choose_bin(self.bin_sample_order, self.values_sampled)\n",
    "        \n",
    "    def report(self, alpha):\n",
    "        history = get_full_history(self.bin_sample_order, self.values_sampled)\n",
    "        bin_history = history[num_draws - 1][self.bin_choice]\n",
    "        self.reported_results = self.strategy_report.report(self.reporting_setting.name, alpha, bin_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fd2cf3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a data structure that shows, on each draw, the values seen in each bin at that point\n",
    "def get_full_history(bin_sample_order, values_sampled):\n",
    "    history = {draw_number: {bin_number: [] for bin_number in range(num_bins)} for draw_number in range(num_draws)}\n",
    "\n",
    "    for draw in range(len(bin_sample_order)):\n",
    "        if draw == 0:\n",
    "            history[draw][bin_sample_order[draw]].append(values_sampled[draw])\n",
    "        else:\n",
    "            prev_history = history[draw - 1].copy()\n",
    "            for bin_num in prev_history:\n",
    "                if bin_num == bin_sample_order[draw]:\n",
    "                    history[draw][bin_num] = prev_history[bin_num] + [values_sampled[draw]]\n",
    "                else:\n",
    "                    history[draw][bin_num] = prev_history[bin_num][:]\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a38bb0c",
   "metadata": {},
   "source": [
    "# Hypothesized Participant Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b7a73c",
   "metadata": {},
   "source": [
    "### Gathering Strategies\n",
    "There are three hypothesized strategies that participants will use to gather data\n",
    "1. **Epsilon-Greedy**: It explores with probability epsilon and exploits with probability 1-epsilon. It's a basic strategy that balances exploration and exploitation. If your data shows a relatively uniform exploration of different options, with no clear bias toward exploiting a specific action, it might align with the epsilon-greedy pattern. If your data reflects a balance between trying out different options to gather information and exploiting the currently best-known option, it may be consistent with epsilon-greedy. (Look for uniform explanation and balanced trade-offs between exploring and exploiting)\n",
    "2. **Thompson Sampling**: Thompson Sampling is a Bayesian approach to the multi-armed bandit problem. It models uncertainty using a probability distribution over the parameters and samples from this distribution to make decisions. It tends to perform well in various scenarios.\n",
    "3. **Win-Stay, Lose-Shift**: The idea is to exploit actions that have been successful in the past (win-stay) and explore alternative actions when faced with failures (lose-shift).\n",
    "4. AdaptiveGatheringStrategy\n",
    "5. ConservativeGatheringStrategy\n",
    "6. Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "105a6444",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpsilonGreedy():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def draw(self, draw_number, bin_sample_order, values_sampled):\n",
    "        epsilon = 0.5\n",
    "        \n",
    "        # chooses random bin first\n",
    "        if draw_number == 0:\n",
    "            return(random.randint(0, num_bins - 1), random.choice([0, 1]))\n",
    "        \n",
    "        # finds the best bin\n",
    "        history = get_full_history(bin_sample_order, values_sampled)\n",
    "        best_bin = 0\n",
    "        best_ratio = 0\n",
    "        \n",
    "        for bin_num in history[draw_number - 1]:\n",
    "            num_zeros = history[draw_number - 1][bin_num].count(0)\n",
    "            num_ones = history[draw_number - 1][bin_num].count(1)\n",
    "\n",
    "            # you've sampled from the bin and it's the best so far\n",
    "            if (num_ones + num_zeros != 0) and (num_ones/(num_ones + num_zeros) > best_ratio):\n",
    "                best_ratio = num_ones/(num_ones + num_zeros)\n",
    "                best_bin = bin_num\n",
    "                \n",
    "        # explore with probability epsilon, exploit otherwise\n",
    "        random_number = random.uniform(0, 1)\n",
    "        if random_number <= epsilon:\n",
    "            bin_number = random.randint(0, num_bins - 1)\n",
    "        else:\n",
    "            bin_number = best_bin\n",
    "        \n",
    "        value = random.choice([0, 1])\n",
    "        return(bin_number, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4dc70fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThompsonSampling():\n",
    "    def __init__(self):\n",
    "        # step 1: initialize prior beliefs\n",
    "        self.alpha_priors = np.ones(num_bins)\n",
    "        self.beta_priors = np.ones(num_bins)\n",
    "    \n",
    "    def draw(self, draw_number, bin_sample_order, values_sampled):\n",
    "        # edge case: choose a random first bin\n",
    "        if draw_number == 0:\n",
    "            bin_num = random.randint(0, num_bins - 1)\n",
    "            choice = random.choice([0, 1])\n",
    "            if choice == 1:\n",
    "                self.alpha_priors[bin_num] += 1\n",
    "            else:\n",
    "                self.beta_priors[bin_num] += 1\n",
    "            return (bin_num, choice)\n",
    "        \n",
    "        # step 2: action selection\n",
    "        bin_samples = []\n",
    "        for bin_number in range(0, num_bins):\n",
    "            sample = beta.rvs(self.alpha_priors[bin_number], self.beta_priors[bin_number])\n",
    "            bin_samples.append(sample)\n",
    "        best_bin = np.argmax(bin_samples)\n",
    "        \n",
    "        # step 3: observe reward\n",
    "        value = random.choice([0, 1])\n",
    "        \n",
    "        # step 4: update probability distribution\n",
    "        if value == 1:\n",
    "            self.alpha_priors[best_bin] += 1\n",
    "        else:\n",
    "            self.beta_priors[best_bin] += 1 \n",
    "        \n",
    "        return best_bin, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bb39fd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveGatheringStrategy():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def draw(self, draw_number, bin_sample_order, values_sampled):\n",
    "        # first half: random\n",
    "        if draw_number < num_draws/2:\n",
    "            bin_number = random.randint(0, num_bins - 1)\n",
    "        \n",
    "        # second half: choose best bin so far\n",
    "        else:\n",
    "            history = get_full_history(bin_sample_order, values_sampled)\n",
    "            \n",
    "            # pick the bin that you've seen the greatest proportion of positive values\n",
    "            best_bin = 0\n",
    "            best_ratio = 0\n",
    "            for bin_num in history[draw_number - 1]:\n",
    "                num_zeros = history[draw_number - 1][bin_num].count(0)\n",
    "                num_ones = history[draw_number - 1][bin_num].count(1)\n",
    "                \n",
    "                # you've sampled from the bin and it's the best so far\n",
    "                if (num_ones + num_zeros != 0) and (num_ones/(num_ones + num_zeros) > best_ratio):\n",
    "                    best_ratio = num_ones/(num_ones + num_zeros)\n",
    "                    best_bin = bin_num\n",
    "            \n",
    "            bin_number = best_bin\n",
    "            \n",
    "        value = random.choice([0, 1])\n",
    "        return(bin_number, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "105a4755",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConservativeGatheringStrategy():\n",
    "    def __init__(self):\n",
    "        self.best_bin_at_halfway = -1\n",
    "    \n",
    "    def draw(self, draw_number, bin_sample_order, values_sampled):\n",
    "        # first half: random\n",
    "        if draw_number < num_draws/2:\n",
    "            bin_number = random.randint(0, num_bins - 1)\n",
    "         \n",
    "        # second half: choose best bin at halfway point\n",
    "        else:\n",
    "            # if you've never chosen the best bin so far, pick one with the greatest proportion of positive values\n",
    "            if (self.best_bin_at_halfway == -1):\n",
    "                history = get_full_history(bin_sample_order, values_sampled)\n",
    "                best_bin = 0\n",
    "                best_ratio = 0\n",
    "                for bin_num in history[draw_number - 1]:\n",
    "                    num_zeros = history[draw_number - 1][bin_num].count(0)\n",
    "                    num_ones = history[draw_number - 1][bin_num].count(1)\n",
    "\n",
    "                    # you've sampled from the bin and it's the best so far\n",
    "                    if (num_ones + num_zeros != 0) and (num_ones/(num_ones + num_zeros) > best_ratio):\n",
    "                        best_ratio = num_ones/(num_ones + num_zeros)\n",
    "                        best_bin = bin_num\n",
    "                self.best_bin_at_halfway = best_bin\n",
    "                \n",
    "            # case where you've only seen negative results\n",
    "            if (self.best_bin_at_halfway == -1):\n",
    "                self.best_bin_at_halfway = 0\n",
    "            \n",
    "            bin_number = self.best_bin_at_halfway\n",
    "            \n",
    "        value = random.choice([0, 1])\n",
    "        return(bin_number, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8f64893e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WinStayLoseShift():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def draw(self, draw_number, bin_sample_order, values_sampled):        \n",
    "        choice = random.choice([0, 1])\n",
    "        \n",
    "        if draw_number == 0:\n",
    "            bin_num = random.randint(0, num_bins - 1)\n",
    "            return (bin_num, choice)\n",
    "       \n",
    "        last_sample = values_sampled[draw_number - 1]\n",
    "        if last_sample == 1:\n",
    "            bin_num = bin_sample_order[draw_number - 1]\n",
    "        elif last_sample == 0:\n",
    "            bin_num = random.randint(0, num_bins - 1)\n",
    "    \n",
    "        return(bin_num, choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fc5f1d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Random():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def draw(self, draw_number, bin_sample_order, values_sampled):        \n",
    "        choice = random.choice([0, 1])\n",
    "        bin_num = random.randint(0, num_bins - 1)\n",
    "        return (bin_num, choice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d17c39a",
   "metadata": {},
   "source": [
    "### Bin-Choosing Strategies\n",
    "We hypothesize that participants could use one of the following strategies for how to choose the single bin whose results they will be asked to report.\n",
    "1. **Maximum Data**: Choose the bin for which you have collected the most data\n",
    "2. **Maximum Success Rate**: Choose the bin for which you have the highest success rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f6a3fade",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaximumDataChoosingStrategy():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    # bin for which you've collected the most data\n",
    "    def choose_bin(self, bin_sample_order, values_sampled):\n",
    "        history = get_full_history(participant.bin_sample_order, participant.values_sampled)\n",
    "        bin_with_most_data = -1\n",
    "        most_draws = 0\n",
    "        \n",
    "        for bin_num in history[num_draws -1]:\n",
    "            num_draws_in_bin = len(history[num_draws -1][bin_num])\n",
    "            if num_draws_in_bin > most_draws:\n",
    "                most_draws = num_draws_in_bin\n",
    "                bin_with_most_data = bin_num\n",
    "                \n",
    "        return(bin_with_most_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "14f039a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaximumSuccessChoosingStrategy():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    # bin for which you have the highest success rate\n",
    "    def choose_bin(self, bin_sample_order, values_sampled):\n",
    "        history = get_full_history(bin_sample_order, values_sampled)\n",
    "        best_bin = 0\n",
    "        best_ratio = 0\n",
    "        \n",
    "        for bin_num in history[num_draws - 1]:\n",
    "            num_zeros = history[num_draws - 1][bin_num].count(0)\n",
    "            num_ones = history[num_draws - 1][bin_num].count(1)\n",
    "\n",
    "            # you've sampled from the bin and it's the best so far\n",
    "            if (num_ones + num_zeros != 0) and (num_ones/(num_ones + num_zeros) > best_ratio):\n",
    "                best_ratio = num_ones/(num_ones + num_zeros)\n",
    "                best_bin = bin_num\n",
    "                    \n",
    "        return(best_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49734e71",
   "metadata": {},
   "source": [
    "### Reporting Strategies\n",
    "We hypothesize that the participants will report their results with some degree $\\alpha$ of exaggeration. When $\\alpha = 0$, this reduces to the strategy of reporting honest, unmanipulated results. When $\\alpha = 1$, this reduces to the strategy of reporting maximum values.\n",
    "- Softmax over the utility function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7fb3cf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportingStrategy():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def report(self, reporting_setting, alpha, bin_history):\n",
    "        num_zeros = bin_history.count(0)\n",
    "        num_ones = bin_history.count(1)\n",
    "        \n",
    "        if alpha < 0 or alpha > 1:\n",
    "            raise ValueError(\"Alpha must be between 0 and 1\")\n",
    "        \n",
    "        # overreport by a proportion of alpha of the remaining rate to get to a value of 1\n",
    "        if reporting_setting == \"rate\":\n",
    "            if num_ones + num_zeros == 0:\n",
    "                accurate_rate = 0.5\n",
    "            else:\n",
    "                accurate_rate = num_ones / (num_ones + num_zeros)\n",
    "            return(accurate_rate + alpha * (1 - accurate_rate))\n",
    "            \n",
    "        # overreport the number of '1's and underreport the number of '0's by a rate of alpha \n",
    "        elif reporting_setting == \"data\":\n",
    "            num_reported_zeros = round(num_zeros * (1 - alpha))\n",
    "            num_reported_ones = round(num_ones * (1 + alpha))\n",
    "            return({\"0\": num_reported_zeros, \"1\": num_reported_ones})\n",
    "        \n",
    "        # remove (100 * alpha)% of the '0' results\n",
    "        elif reporting_setting == \"subset\":\n",
    "            num_reported_zeros = round(num_zeros * (1 - alpha))\n",
    "            return({\"0\": num_reported_zeros, \"1\": num_ones})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54eda93c",
   "metadata": {},
   "source": [
    "# Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3325450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_participants(gathering_strategy, bin_choosing_strategy, reporting_strategy, setting, alpha_value):\n",
    "    participants = []\n",
    "\n",
    "    # make all 100 participants\n",
    "    for i in range (0, 100):\n",
    "        # initialize gathering strategy\n",
    "        if gathering_strategy == \"random\":\n",
    "            strat_gather = Random()\n",
    "        elif gathering_strategy == \"eg\":\n",
    "            strat_gather = EpsilonGreedy()\n",
    "        elif gathering_strategy == \"ts\":\n",
    "            strat_gather = ThompsonSampling()\n",
    "        elif gathering_strategy == \"ag\":\n",
    "            strat_gather = AdaptiveGatheringStrategy()\n",
    "        elif gathering_strategy == \"cg\":\n",
    "            strat_gather = ConservativeGatheringStrategy()\n",
    "        elif gathering_strategy == \"wsls\":\n",
    "            strat_gather = WinStayLoseShift()\n",
    "\n",
    "        # initialize bin choosing strategy\n",
    "        if bin_choosing_strategy == \"maxd\":\n",
    "            strat_bin = MaximumDataChoosingStrategy()\n",
    "        elif bin_choosing_strategy == \"maxs\":\n",
    "            strat_bin = MaximumSuccessChoosingStrategy()\n",
    "\n",
    "        # initialize reporting strategy\n",
    "        if reporting_strategy == \"rs\":\n",
    "            strat_report = ReportingStrategy()\n",
    "\n",
    "        # initialize setting\n",
    "        if setting == \"rate\":\n",
    "            report_set = ReportingSetting(\"rate\")\n",
    "        elif setting == \"data\":\n",
    "            report_set = ReportingSetting(\"data\")\n",
    "        elif setting == \"subset\":\n",
    "            report_set = ReportingSetting(\"subset\")\n",
    "\n",
    "        # make participant\n",
    "        participant = Participant(strategy_gather=strat_gather, strategy_bin=strat_bin, strategy_report=strat_report, reporting_setting=report_set)\n",
    "\n",
    "        # sample\n",
    "        for i in range(0, num_draws):\n",
    "            participant.sample()\n",
    "\n",
    "        # choose the bin\n",
    "        participant.choose_bin(participant.bin_sample_order, participant.values_sampled)\n",
    "\n",
    "        # specify alpha value\n",
    "        participant.report(alpha_value)\n",
    "                        \n",
    "        participants.append(participant)\n",
    "\n",
    "    return(participants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "645bddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gathering_strategies = [\"random\", \"eg\", \"ts\", \"ag\", \"cg\", \"wsls\"]\n",
    "bin_choosing_strategies = [\"maxd\", \"maxs\"]\n",
    "reporting_strategies = [\"rs\"]\n",
    "reporting_setting = [\"rate\", \"data\", \"subset\"]\n",
    "alpha_values = [0, 0.25, 0.5, 1]\n",
    "\n",
    "gathering_strategies = [\"random\"]\n",
    "bin_choosing_strategies = [\"maxd\"]\n",
    "reporting_strategies = [\"rs\"]\n",
    "reporting_setting = [\"rate\"]\n",
    "alpha_values = [0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "28e3bcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peer_review(participants):\n",
    "    return(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "36fb17c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gathering_strategy in gathering_strategies:\n",
    "    for bin_choosing_strategy in bin_choosing_strategies:\n",
    "        for reporting_strategy in reporting_strategies:\n",
    "            for setting in reporting_setting:\n",
    "                for alpha_value in alpha_values:\n",
    "                    participants = make_participants(gathering_strategy, bin_choosing_strategy, reporting_strategy, setting, alpha_value)\n",
    "                    results = peer_review(participants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37004210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a584f75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf72ca6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a46c1cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd1547d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f15482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510d4abb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aea3db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa41aa9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38081ece",
   "metadata": {},
   "source": [
    "# Extra Scratch Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c14e0d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant History\n",
      "{0: {0: [], 1: [], 2: [1]}, 1: {0: [], 1: [0], 2: [1]}, 2: {0: [], 1: [0, 0], 2: [1]}, 3: {0: [], 1: [0, 0, 1], 2: [1]}, 4: {0: [1], 1: [0, 0, 1], 2: [1]}, 5: {0: [1, 0], 1: [0, 0, 1], 2: [1]}, 6: {0: [1, 0], 1: [0, 0, 1], 2: [1, 0]}, 7: {0: [1, 0, 0], 1: [0, 0, 1], 2: [1, 0]}, 8: {0: [1, 0, 0, 0], 1: [0, 0, 1], 2: [1, 0]}, 9: {0: [1, 0, 0, 0], 1: [0, 0, 1, 1], 2: [1, 0]}}\n",
      "\n",
      "Bins sampled, in order\n",
      "[2, 1, 1, 1, 0, 0, 2, 0, 0, 1]\n",
      "\n",
      "Values Sampled, in order\n",
      "[1, 0, 0, 1, 1, 0, 0, 0, 0, 1]\n",
      "\n",
      "Bin Chosen\n",
      "0\n",
      "\n",
      "Reported results\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "strat_gather = Random()\n",
    "# strat_gather = EpsilonGreedy()\n",
    "# strat_gather = ThompsonSampling()\n",
    "# strat_gather = AdaptiveGatheringStrategy()\n",
    "# strat_gather = ConservativeGatheringStrategy()\n",
    "# strat_gather = WinStayLoseShift()\n",
    "\n",
    "strat_bin = MaximumDataChoosingStrategy()\n",
    "# strat_bin = MaximumSuccessChoosingStrategy()\n",
    "\n",
    "strat_report = ReportingStrategy()\n",
    "\n",
    "report_set = ReportingSetting(\"rate\")\n",
    "# report_set = ReportingSetting(\"data\")\n",
    "# report_set = ReportingSetting(\"subset\")\n",
    "\n",
    "participant = Participant(strategy_gather=strat_gather, strategy_bin=strat_bin, strategy_report=strat_report, reporting_setting=report_set)\n",
    "\n",
    "for i in range(0, num_draws):\n",
    "    participant.sample()\n",
    "    \n",
    "print('Participant History')\n",
    "print(get_full_history(participant.bin_sample_order, participant.values_sampled))\n",
    "print()\n",
    "print('Bins sampled, in order')\n",
    "print(participant.bin_sample_order)\n",
    "print()\n",
    "print('Values Sampled, in order')\n",
    "print(participant.values_sampled)\n",
    "print()\n",
    "print('Bin Chosen')\n",
    "participant.choose_bin(participant.bin_sample_order, participant.values_sampled)\n",
    "print(participant.bin_choice)\n",
    "print()\n",
    "print(\"Reported results\")\n",
    "participant.report(0)\n",
    "print(participant.reported_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4362c6e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a402876",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
