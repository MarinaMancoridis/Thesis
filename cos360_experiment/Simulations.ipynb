{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ee15324",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook explores how different simulation settings affect the frequency of false results being published in a pseudo-scientific setting. It demonstrates that sevearal hypothesized effects emerged in single-generation simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "d98c1ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from scipy.stats import beta, binom\n",
    "import random\n",
    "import json\n",
    "\n",
    "# simulation-wide global variables\n",
    "num_bins = 3\n",
    "num_draws = 10\n",
    "num_participants = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8595c6c",
   "metadata": {},
   "source": [
    "###  Reporting Settings\n",
    "A participant is in one of three settings for how they are allowed to report their data\n",
    "1. **Rate**: Pick a single bin and report the survival rate of its pill contents.\n",
    "2. **Data**: Pick a single bin and report the total number of rats that died and rats that stayed alive\n",
    "3. **Subset**: Pick a single bin and choose a set of data to publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "5719f0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportingSetting:\n",
    "    def __init__(self, name):\n",
    "        if name not in {\"rate\", \"data\", \"subset\"}:\n",
    "            raise ValueError(\"Improper setting name\")\n",
    "        self.name = name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9668707f",
   "metadata": {},
   "source": [
    "### Participants\n",
    "A participant implements a given strategy for how they gather data and a strategy for how they report data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "d2d9a5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Participant:\n",
    "    next_id = 1  # Class variable to keep track of the next available ID\n",
    "\n",
    "    def __init__(self, strategy_gather, strategy_bin, strategy_report, reporting_setting):        \n",
    "        self.id = Participant.next_id  # Assign a unique ID to the participant\n",
    "        Participant.next_id += 1  # Update the next available ID for the next participant\n",
    "\n",
    "        self.strategy_gather = strategy_gather                               # strategy to collect data\n",
    "        self.strategy_bin = strategy_bin                                     # strategy to select bin to report\n",
    "        self.strategy_report = strategy_report                               # strategy to report data in the chosen bin\n",
    "        self.reporting_setting = reporting_setting                           # type of report a participant can make\n",
    "        self.bin_sample_order = []                                           # order of bins sampled\n",
    "        self.values_sampled = []                                             # values received across draws\n",
    "        self.bin_choice = -1                                                 # the bin chosen to be reported\n",
    "        reported_results = None                                              # the results reported\n",
    "        \n",
    "    def sample(self):\n",
    "        sample_number = len(self.bin_sample_order)\n",
    "        bin_number, value = self.strategy_gather.draw(len(self.values_sampled), self.bin_sample_order, self.values_sampled)\n",
    "        self.bin_sample_order.append(bin_number)\n",
    "        self.values_sampled.append(value)\n",
    "        \n",
    "    def choose_bin(self, bin_sample_order, values_sampled):\n",
    "        self.bin_choice = self.strategy_bin.choose_bin(self.bin_sample_order, self.values_sampled)\n",
    "        \n",
    "    def report(self, alpha):\n",
    "        history = get_full_history(self.bin_sample_order, self.values_sampled)\n",
    "        bin_history = history[num_draws - 1][self.bin_choice]\n",
    "        self.reported_results = self.strategy_report.report(self.reporting_setting.name, alpha, bin_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "fd2cf3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a data structure that shows, on each draw, the values seen in each bin at that point\n",
    "def get_full_history(bin_sample_order, values_sampled):\n",
    "    history = {draw_number: {bin_number: [] for bin_number in range(num_bins)} for draw_number in range(num_draws)}\n",
    "\n",
    "    for draw in range(len(bin_sample_order)):\n",
    "        if draw == 0:\n",
    "            history[draw][bin_sample_order[draw]].append(values_sampled[draw])\n",
    "        else:\n",
    "            prev_history = history[draw - 1].copy()\n",
    "            for bin_num in prev_history:\n",
    "                if bin_num == bin_sample_order[draw]:\n",
    "                    history[draw][bin_num] = prev_history[bin_num] + [values_sampled[draw]]\n",
    "                else:\n",
    "                    history[draw][bin_num] = prev_history[bin_num][:]\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a38bb0c",
   "metadata": {},
   "source": [
    "# Hypothesized Participant Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b7a73c",
   "metadata": {},
   "source": [
    "### Gathering Strategies\n",
    "There are three hypothesized strategies that participants will use to gather data\n",
    "1. **Epsilon-Greedy**: It explores with probability epsilon and exploits with probability 1-epsilon. It's a basic strategy that balances exploration and exploitation. If your data shows a relatively uniform exploration of different options, with no clear bias toward exploiting a specific action, it might align with the epsilon-greedy pattern. If your data reflects a balance between trying out different options to gather information and exploiting the currently best-known option, it may be consistent with epsilon-greedy. (Look for uniform explanation and balanced trade-offs between exploring and exploiting)\n",
    "2. **Thompson Sampling**: Thompson Sampling is a Bayesian approach to the multi-armed bandit problem. It models uncertainty using a probability distribution over the parameters and samples from this distribution to make decisions. It tends to perform well in various scenarios.\n",
    "3. **Win-Stay, Lose-Shift**: The idea is to exploit actions that have been successful in the past (win-stay) and explore alternative actions when faced with failures (lose-shift).\n",
    "4. AdaptiveGatheringStrategy\n",
    "5. ConservativeGatheringStrategy\n",
    "6. Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "105a6444",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpsilonGreedy():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def draw(self, draw_number, bin_sample_order, values_sampled):\n",
    "        epsilon = 0.5\n",
    "        \n",
    "        # chooses random bin first\n",
    "        if draw_number == 0:\n",
    "            return(random.randint(0, num_bins - 1), random.choice([0, 1]))\n",
    "        \n",
    "        # finds the best bin\n",
    "        history = get_full_history(bin_sample_order, values_sampled)\n",
    "        best_bin = 0\n",
    "        best_ratio = 0\n",
    "        \n",
    "        for bin_num in history[draw_number - 1]:\n",
    "            num_zeros = history[draw_number - 1][bin_num].count(0)\n",
    "            num_ones = history[draw_number - 1][bin_num].count(1)\n",
    "\n",
    "            # you've sampled from the bin and it's the best so far\n",
    "            if (num_ones + num_zeros != 0) and (num_ones/(num_ones + num_zeros) > best_ratio):\n",
    "                best_ratio = num_ones/(num_ones + num_zeros)\n",
    "                best_bin = bin_num\n",
    "                \n",
    "        # explore with probability epsilon, exploit otherwise\n",
    "        random_number = random.uniform(0, 1)\n",
    "        if random_number <= epsilon:\n",
    "            bin_number = random.randint(0, num_bins - 1)\n",
    "        else:\n",
    "            bin_number = best_bin\n",
    "        \n",
    "        value = random.choice([0, 1])\n",
    "        return(bin_number, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "4dc70fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThompsonSampling():\n",
    "    def __init__(self):\n",
    "        # step 1: initialize prior beliefs\n",
    "        self.alpha_priors = np.ones(num_bins)\n",
    "        self.beta_priors = np.ones(num_bins)\n",
    "    \n",
    "    def draw(self, draw_number, bin_sample_order, values_sampled):\n",
    "        # edge case: choose a random first bin\n",
    "        if draw_number == 0:\n",
    "            bin_num = random.randint(0, num_bins - 1)\n",
    "            choice = random.choice([0, 1])\n",
    "            if choice == 1:\n",
    "                self.alpha_priors[bin_num] += 1\n",
    "            else:\n",
    "                self.beta_priors[bin_num] += 1\n",
    "            return (bin_num, choice)\n",
    "        \n",
    "        # step 2: action selection\n",
    "        bin_samples = []\n",
    "        for bin_number in range(0, num_bins):\n",
    "            sample = beta.rvs(self.alpha_priors[bin_number], self.beta_priors[bin_number])\n",
    "            bin_samples.append(sample)\n",
    "        best_bin = np.argmax(bin_samples)\n",
    "        \n",
    "        # step 3: observe reward\n",
    "        value = random.choice([0, 1])\n",
    "        \n",
    "        # step 4: update probability distribution\n",
    "        if value == 1:\n",
    "            self.alpha_priors[best_bin] += 1\n",
    "        else:\n",
    "            self.beta_priors[best_bin] += 1 \n",
    "        \n",
    "        return best_bin, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "bb39fd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveGatheringStrategy():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def draw(self, draw_number, bin_sample_order, values_sampled):\n",
    "        # first half: random\n",
    "        if draw_number < num_draws/2:\n",
    "            bin_number = random.randint(0, num_bins - 1)\n",
    "        \n",
    "        # second half: choose best bin so far\n",
    "        else:\n",
    "            history = get_full_history(bin_sample_order, values_sampled)\n",
    "            \n",
    "            # pick the bin that you've seen the greatest proportion of positive values\n",
    "            best_bin = 0\n",
    "            best_ratio = 0\n",
    "            for bin_num in history[draw_number - 1]:\n",
    "                num_zeros = history[draw_number - 1][bin_num].count(0)\n",
    "                num_ones = history[draw_number - 1][bin_num].count(1)\n",
    "                \n",
    "                # you've sampled from the bin and it's the best so far\n",
    "                if (num_ones + num_zeros != 0) and (num_ones/(num_ones + num_zeros) > best_ratio):\n",
    "                    best_ratio = num_ones/(num_ones + num_zeros)\n",
    "                    best_bin = bin_num\n",
    "            \n",
    "            bin_number = best_bin\n",
    "            \n",
    "        value = random.choice([0, 1])\n",
    "        return(bin_number, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "105a4755",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConservativeGatheringStrategy():\n",
    "    def __init__(self):\n",
    "        self.best_bin_at_halfway = -1\n",
    "    \n",
    "    def draw(self, draw_number, bin_sample_order, values_sampled):\n",
    "        # first half: random\n",
    "        if draw_number < num_draws/2:\n",
    "            bin_number = random.randint(0, num_bins - 1)\n",
    "         \n",
    "        # second half: choose best bin at halfway point\n",
    "        else:\n",
    "            # if you've never chosen the best bin so far, pick one with the greatest proportion of positive values\n",
    "            if (self.best_bin_at_halfway == -1):\n",
    "                history = get_full_history(bin_sample_order, values_sampled)\n",
    "                best_bin = 0\n",
    "                best_ratio = 0\n",
    "                for bin_num in history[draw_number - 1]:\n",
    "                    num_zeros = history[draw_number - 1][bin_num].count(0)\n",
    "                    num_ones = history[draw_number - 1][bin_num].count(1)\n",
    "\n",
    "                    # you've sampled from the bin and it's the best so far\n",
    "                    if (num_ones + num_zeros != 0) and (num_ones/(num_ones + num_zeros) > best_ratio):\n",
    "                        best_ratio = num_ones/(num_ones + num_zeros)\n",
    "                        best_bin = bin_num\n",
    "                self.best_bin_at_halfway = best_bin\n",
    "                \n",
    "            # case where you've only seen negative results\n",
    "            if (self.best_bin_at_halfway == -1):\n",
    "                self.best_bin_at_halfway = 0\n",
    "            \n",
    "            bin_number = self.best_bin_at_halfway\n",
    "            \n",
    "        value = random.choice([0, 1])\n",
    "        return(bin_number, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "8f64893e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WinStayLoseShift():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def draw(self, draw_number, bin_sample_order, values_sampled):        \n",
    "        choice = random.choice([0, 1])\n",
    "        \n",
    "        if draw_number == 0:\n",
    "            bin_num = random.randint(0, num_bins - 1)\n",
    "            return (bin_num, choice)\n",
    "       \n",
    "        last_sample = values_sampled[draw_number - 1]\n",
    "        if last_sample == 1:\n",
    "            bin_num = bin_sample_order[draw_number - 1]\n",
    "        elif last_sample == 0:\n",
    "            bin_num = random.randint(0, num_bins - 1)\n",
    "    \n",
    "        return(bin_num, choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "fc5f1d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Random():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def draw(self, draw_number, bin_sample_order, values_sampled):        \n",
    "        choice = random.choice([0, 1])\n",
    "        bin_num = random.randint(0, num_bins - 1)\n",
    "        return (bin_num, choice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d17c39a",
   "metadata": {},
   "source": [
    "### Bin-Choosing Strategies\n",
    "We hypothesize that participants could use one of the following strategies for how to choose the single bin whose results they will be asked to report.\n",
    "1. **Maximum Data**: Choose the bin for which you have collected the most data\n",
    "2. **Maximum Success Rate**: Choose the bin for which you have the highest success rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "f6a3fade",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaximumDataChoosingStrategy():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    # bin for which you've collected the most data\n",
    "    def choose_bin(self, bin_sample_order, values_sampled):\n",
    "        history = get_full_history(participant.bin_sample_order, participant.values_sampled)\n",
    "        bin_with_most_data = -1\n",
    "        most_draws = 0\n",
    "        \n",
    "        for bin_num in history[num_draws -1]:\n",
    "            num_draws_in_bin = len(history[num_draws -1][bin_num])\n",
    "            if num_draws_in_bin > most_draws:\n",
    "                most_draws = num_draws_in_bin\n",
    "                bin_with_most_data = bin_num\n",
    "                \n",
    "        return(bin_with_most_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "14f039a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaximumSuccessChoosingStrategy():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    # bin for which you have the highest success rate\n",
    "    def choose_bin(self, bin_sample_order, values_sampled):\n",
    "        history = get_full_history(bin_sample_order, values_sampled)\n",
    "        best_bin = 0\n",
    "        best_ratio = 0\n",
    "        \n",
    "        for bin_num in history[num_draws - 1]:\n",
    "            num_zeros = history[num_draws - 1][bin_num].count(0)\n",
    "            num_ones = history[num_draws - 1][bin_num].count(1)\n",
    "\n",
    "            # you've sampled from the bin and it's the best so far\n",
    "            if (num_ones + num_zeros != 0) and (num_ones/(num_ones + num_zeros) > best_ratio):\n",
    "                best_ratio = num_ones/(num_ones + num_zeros)\n",
    "                best_bin = bin_num\n",
    "                    \n",
    "        return(best_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49734e71",
   "metadata": {},
   "source": [
    "### Reporting Strategies\n",
    "We hypothesize that the participants will report their results with some degree $\\alpha$ of exaggeration. When $\\alpha = 0$, this reduces to the strategy of reporting honest, unmanipulated results. When $\\alpha = 1$, this reduces to the strategy of reporting maximum values.\n",
    "- Softmax over the utility function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "7fb3cf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportingStrategy():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def report(self, reporting_setting, alpha, bin_history):\n",
    "        num_zeros = bin_history.count(0)\n",
    "        num_ones = bin_history.count(1)\n",
    "        \n",
    "        if alpha < 0 or alpha > 1:\n",
    "            raise ValueError(\"Alpha must be between 0 and 1\")\n",
    "        \n",
    "        # overreport by a proportion of alpha of the remaining rate to get to a value of 1\n",
    "        if reporting_setting == \"rate\":\n",
    "            if num_ones + num_zeros == 0:\n",
    "                accurate_rate = 0.5\n",
    "            else:\n",
    "                accurate_rate = num_ones / (num_ones + num_zeros)\n",
    "            return(accurate_rate + alpha * (1 - accurate_rate))\n",
    "            \n",
    "        # overreport the number of '1's and underreport the number of '0's by a rate of alpha \n",
    "        elif reporting_setting == \"data\":\n",
    "            num_reported_zeros = round(num_zeros * (1 - alpha))\n",
    "            num_reported_ones = round(num_ones * (1 + alpha))\n",
    "            return({\"0\": num_reported_zeros, \"1\": num_reported_ones})\n",
    "        \n",
    "        # remove (100 * alpha)% of the '0' results\n",
    "        elif reporting_setting == \"subset\":\n",
    "            num_reported_zeros = round(num_zeros * (1 - alpha))\n",
    "            return({\"0\": num_reported_zeros, \"1\": num_ones})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54eda93c",
   "metadata": {},
   "source": [
    "# Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "3325450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_participants(gathering_strategy, bin_choosing_strategy, reporting_strategy, setting, alpha_value):\n",
    "    participants = []\n",
    "\n",
    "    # make all 100 participants\n",
    "    for i in range (0, 100):\n",
    "        # initialize gathering strategy\n",
    "        if gathering_strategy == \"random\":\n",
    "            strat_gather = Random()\n",
    "        elif gathering_strategy == \"eg\":\n",
    "            strat_gather = EpsilonGreedy()\n",
    "        elif gathering_strategy == \"ts\":\n",
    "            strat_gather = ThompsonSampling()\n",
    "        elif gathering_strategy == \"ag\":\n",
    "            strat_gather = AdaptiveGatheringStrategy()\n",
    "        elif gathering_strategy == \"cg\":\n",
    "            strat_gather = ConservativeGatheringStrategy()\n",
    "        elif gathering_strategy == \"wsls\":\n",
    "            strat_gather = WinStayLoseShift()\n",
    "\n",
    "        # initialize bin choosing strategy\n",
    "        if bin_choosing_strategy == \"maxd\":\n",
    "            strat_bin = MaximumDataChoosingStrategy()\n",
    "        elif bin_choosing_strategy == \"maxs\":\n",
    "            strat_bin = MaximumSuccessChoosingStrategy()\n",
    "\n",
    "        # initialize reporting strategy\n",
    "        if reporting_strategy == \"rs\":\n",
    "            strat_report = ReportingStrategy()\n",
    "\n",
    "        # initialize setting\n",
    "        if setting == \"rate\":\n",
    "            report_set = ReportingSetting(\"rate\")\n",
    "        elif setting == \"data\":\n",
    "            report_set = ReportingSetting(\"data\")\n",
    "        elif setting == \"subset\":\n",
    "            report_set = ReportingSetting(\"subset\")\n",
    "\n",
    "        # make participant\n",
    "        participant = Participant(strategy_gather=strat_gather, strategy_bin=strat_bin, strategy_report=strat_report, reporting_setting=report_set)\n",
    "\n",
    "        # sample\n",
    "        for i in range(0, num_draws):\n",
    "            participant.sample()\n",
    "\n",
    "        # choose the bin\n",
    "        participant.choose_bin(participant.bin_sample_order, participant.values_sampled)\n",
    "\n",
    "        # specify alpha value\n",
    "        participant.report(alpha_value)\n",
    "                        \n",
    "        participants.append(participant)\n",
    "\n",
    "    return(participants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "b2ed316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peer_review(participants):    \n",
    "    rates = [participant.reported_results for participant in participants if participant.reporting_setting.name == \"rate\"]\n",
    "\n",
    "    if rates:\n",
    "        final_reports = {}\n",
    "        percentiles = np.percentile(rates, np.arange(0, 101, 1))\n",
    "        \n",
    "        for participant in participants:\n",
    "            if participant.reporting_setting.name == \"rate\":\n",
    "                reported_rate = participant.reported_results\n",
    "                percentile_rank = np.searchsorted(percentiles, reported_rate) / len(percentiles) * 100\n",
    "                \n",
    "                final_reports[participant.id] = {\n",
    "                    \"reportedRate\": reported_rate,\n",
    "                    \"score\": percentile_rank / 10\n",
    "                }\n",
    "                \n",
    "        for participant in participants:\n",
    "            if final_reports[participant.id][\"reportedRate\"] > 0.5:\n",
    "                oldScore = final_reports[participant.id][\"score\"]\n",
    "                newScore = oldScore + (10 - oldScore) * 0.05\n",
    "                final_reports[participant.id][\"score\"] = newScore\n",
    "            else:\n",
    "                oldScore = final_reports[participant.id][\"score\"]\n",
    "                newScore = 0.95 * oldScore\n",
    "                final_reports[participant.id][\"score\"] = newScore\n",
    "                \n",
    "                \n",
    "        # Sort participants by score and select the top 20\n",
    "        sorted_participants = sorted(final_reports.items(), key=lambda x: x[1][\"score\"], reverse=True)\n",
    "        top_20_participants = sorted_participants[:20]\n",
    "\n",
    "        # Calculate the percentage difference for each selected participant\n",
    "        percentage_differences = [abs(participant[1][\"reportedRate\"] - 0.5) / 0.5 * 100\n",
    "                                  for participant in top_20_participants]\n",
    "\n",
    "        # Find the average percentage difference\n",
    "        average_percentage_difference = round(np.mean(percentage_differences))\n",
    "\n",
    "        return(average_percentage_difference)\n",
    "    \n",
    "    # if there is data associated with each participant... (subset or full reporting)\n",
    "    else:\n",
    "        final_reports = {}\n",
    "        reported_sums = [participant.reported_results['0'] + participant.reported_results['1']\n",
    "                         for participant in participants]\n",
    "\n",
    "        percentiles = np.percentile(reported_sums, np.arange(0, 101, 1))\n",
    "\n",
    "        for participant in participants:\n",
    "            reported_sum = participant.reported_results['0'] + participant.reported_results['1']\n",
    "            percentile_rank = np.searchsorted(percentiles, reported_sum) / len(percentiles) * 100\n",
    "            \n",
    "            reported_rate = 0\n",
    "            if participant.reported_results['1'] + participant.reported_results['0'] != 0:\n",
    "                reported_rate = participant.reported_results['1'] / (participant.reported_results['1']  + participant.reported_results['0'])\n",
    "            \n",
    "            score = percentile_rank / 10\n",
    "            final_reports[participant.id] = {\n",
    "                    \"reportedSum\": reported_sum,\n",
    "                    \"reportedRate\": reported_rate,\n",
    "                    \"score\": score\n",
    "            }\n",
    "            \n",
    "        # add surprise factor and publishing bias\n",
    "        for participant in participants:\n",
    "            reported_rate = final_reports[participant.id][\"reportedRate\"]\n",
    "            oldScore = final_reports[participant.id][\"score\"]\n",
    "            \n",
    "            newScore = oldScore + (10 - oldScore)*(abs(reported_rate - 0.5)) # surprise factor\n",
    "            \n",
    "            # publishing bias\n",
    "            if reported_rate < 0.5:\n",
    "                newScore = 0.95 * oldScore\n",
    "            else:\n",
    "                newScore = oldScore + (10 - oldScore) * 0.05\n",
    "            \n",
    "            final_reports[participant.id][\"score\"] = newScore\n",
    "            \n",
    "        # Sort participants by score and select the top 20\n",
    "        sorted_participants = sorted(final_reports.items(), key=lambda x: x[1][\"score\"], reverse=True)\n",
    "        top_20_participants = sorted_participants[:20]\n",
    "\n",
    "        # Calculate the percentage difference for each selected participant\n",
    "        percentage_differences = [abs(participant[1][\"reportedRate\"] - 0.5) / 0.5 * 100\n",
    "                                  for participant in top_20_participants]\n",
    "\n",
    "        # Find the average percentage difference\n",
    "        average_percentage_difference = round(np.mean(percentage_differences))\n",
    "\n",
    "        return(average_percentage_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "645bddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gathering_strategies = [\"random\"]\n",
    "# bin_choosing_strategies = [\"maxd\"]\n",
    "# reporting_strategies = [\"rs\"]\n",
    "# reporting_setting = [\"data\"]\n",
    "# alpha_values = [0.5]\n",
    "\n",
    "gathering_strategies = [\"random\", \"eg\", \"ts\", \"ag\", \"cg\", \"wsls\"]\n",
    "bin_choosing_strategies = [\"maxd\", \"maxs\"]\n",
    "reporting_strategies = [\"rs\"]\n",
    "reporting_setting = [\"rate\", \"data\", \"subset\"]\n",
    "alpha_values = [0, 0.25, 0.5, 0.75, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "b749d70f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [375], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m mpe_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_runs):\n\u001b[0;32m---> 16\u001b[0m     participants \u001b[38;5;241m=\u001b[39m \u001b[43mmake_participants\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgathering_strategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbin_choosing_strategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreporting_strategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msetting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     mean_percent_error \u001b[38;5;241m=\u001b[39m peer_review(participants)\n\u001b[1;32m     18\u001b[0m     mpe_list\u001b[38;5;241m.\u001b[39mappend(mean_percent_error)\n",
      "Cell \u001b[0;32mIn [372], line 43\u001b[0m, in \u001b[0;36mmake_participants\u001b[0;34m(gathering_strategy, bin_choosing_strategy, reporting_strategy, setting, alpha_value)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# sample\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, num_draws):\n\u001b[0;32m---> 43\u001b[0m     \u001b[43mparticipant\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# choose the bin\u001b[39;00m\n\u001b[1;32m     46\u001b[0m participant\u001b[38;5;241m.\u001b[39mchoose_bin(participant\u001b[38;5;241m.\u001b[39mbin_sample_order, participant\u001b[38;5;241m.\u001b[39mvalues_sampled)\n",
      "Cell \u001b[0;32mIn [361], line 19\u001b[0m, in \u001b[0;36mParticipant.sample\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     18\u001b[0m     sample_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbin_sample_order)\n\u001b[0;32m---> 19\u001b[0m     bin_number, value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy_gather\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues_sampled\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbin_sample_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues_sampled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbin_sample_order\u001b[38;5;241m.\u001b[39mappend(bin_number)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues_sampled\u001b[38;5;241m.\u001b[39mappend(value)\n",
      "Cell \u001b[0;32mIn [364], line 21\u001b[0m, in \u001b[0;36mThompsonSampling.draw\u001b[0;34m(self, draw_number, bin_sample_order, values_sampled)\u001b[0m\n\u001b[1;32m     19\u001b[0m bin_samples \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bin_number \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, num_bins):\n\u001b[0;32m---> 21\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[43mbeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrvs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha_priors\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbin_number\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta_priors\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbin_number\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     bin_samples\u001b[38;5;241m.\u001b[39mappend(sample)\n\u001b[1;32m     23\u001b[0m best_bin \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(bin_samples)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize the dictionary to store mean percent errors\n",
    "mean_percent_errors_dict = {}\n",
    "\n",
    "# Number of runs for each key\n",
    "num_runs = 10\n",
    "\n",
    "for gathering_strategy in gathering_strategies:\n",
    "    for bin_choosing_strategy in bin_choosing_strategies:\n",
    "        for reporting_strategy in reporting_strategies:\n",
    "            for setting in reporting_setting:\n",
    "                for alpha_value in alpha_values:\n",
    "                    # Initialize a list to store MPE for each run\n",
    "                    mpe_list = []\n",
    "\n",
    "                    for _ in range(num_runs):\n",
    "                        participants = make_participants(gathering_strategy, bin_choosing_strategy, reporting_strategy, setting, alpha_value)\n",
    "                        mean_percent_error = peer_review(participants)\n",
    "                        mpe_list.append(mean_percent_error)\n",
    "\n",
    "                    # Calculate the average MPE\n",
    "                    avg_mpe = np.mean(mpe_list)\n",
    "\n",
    "                    # Create a key based on the variable names\n",
    "                    key = (gathering_strategy, bin_choosing_strategy, reporting_strategy, setting, alpha_value)\n",
    "\n",
    "                    # Store the average MPE in the dictionary\n",
    "                    mean_percent_errors_dict[key] = avg_mpe\n",
    "\n",
    "print(mean_percent_errors_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b08be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tuple keys to strings\n",
    "string_keys_dict = {str(key): value for key, value in mean_percent_errors_dict.items()}\n",
    "\n",
    "# Specify the file path to save the JSON file\n",
    "json_file_path = 'mean_percent_errors.json'\n",
    "\n",
    "# Save the dictionary with string keys to a JSON file\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(string_keys_dict, json_file)\n",
    "\n",
    "print(f\"Mean percent errors saved to {json_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516c4543",
   "metadata": {},
   "source": [
    "### Find best 5 and worst 5 settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05316144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tuple keys to strings\n",
    "string_keys_dict = {str(key): value for key, value in mean_percent_errors_dict.items()}\n",
    "\n",
    "# Sort the dictionary by values\n",
    "sorted_dict = dict(sorted(string_keys_dict.items(), key=lambda item: item[1]))\n",
    "\n",
    "# Print the best five settings with their MPE\n",
    "print(\"Best 15 Settings:\")\n",
    "for key in list(sorted_dict)[:15]:\n",
    "    setting_tuple = eval(key)  # Convert the string back to a tuple\n",
    "    mpe = sorted_dict[key]\n",
    "    print(f\"{setting_tuple}: {mpe}\")\n",
    "\n",
    "# Print the worst five settings with their MPE\n",
    "print(\"\\nWorst 15 Settings:\")\n",
    "for key in list(sorted_dict)[-15:]:\n",
    "    setting_tuple = eval(key)  # Convert the string back to a tuple\n",
    "    mpe = sorted_dict[key]\n",
    "    print(f\"{setting_tuple}: {mpe}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d195a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tuple keys to strings\n",
    "string_keys_dict = {str(key): value for key, value in mean_percent_errors_dict.items()}\n",
    "\n",
    "# Filter out settings where alpha is equal to 1\n",
    "filtered_dict = {key: value for key, value in string_keys_dict.items() if eval(key)[-1] != 1}\n",
    "\n",
    "# Sort the filtered dictionary by values in descending order\n",
    "sorted_filtered_dict = dict(sorted(filtered_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "r\n",
    "# Print the worst settings with alpha not equal to 1\n",
    "print(\"Worst Settings (alpha not equal to 1) in Order:\")\n",
    "for key, value in sorted_filtered_dict.items():\n",
    "    setting_tuple = eval(key)  # Convert the string back to a tuple\n",
    "    print(f\"{setting_tuple}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77830cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Convert tuple keys to strings\n",
    "string_keys_dict = {str(key): value for key, value in mean_percent_errors_dict.items()}\n",
    "\n",
    "# Create a defaultdict to store MPE values for each unique setting component\n",
    "component_mpes = defaultdict(list)\n",
    "\n",
    "# Populate the defaultdict with MPE values\n",
    "for key, value in string_keys_dict.items():\n",
    "    setting_tuple = eval(key)\n",
    "    \n",
    "    # Iterate over all components in the setting tuple\n",
    "    for component in setting_tuple:\n",
    "        component_mpes[component].append(value)\n",
    "\n",
    "# Calculate average MPE for each unique setting component\n",
    "average_mpes = {component: np.mean(mpe_list) for component, mpe_list in component_mpes.items()}\n",
    "\n",
    "# Print the average MPE for each setting component\n",
    "print(\"Average MPE for Each Setting Component:\")\n",
    "for component, average_mpe in average_mpes.items():\n",
    "    print(f\"{component}: {average_mpe}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d362ceb0",
   "metadata": {},
   "source": [
    "### Setting corresponding to what the experiment showed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce20adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tuple keys to strings\n",
    "string_keys_dict = {str(key): value for key, value in mean_percent_errors_dict.items()}\n",
    "\n",
    "# Specify the criteria for finding the entry\n",
    "target_key = \"('wsls', 'maxd', 'rs', 'data', 0.25)\"\n",
    "\n",
    "# Find and print the entry based on the specified criteria\n",
    "if target_key in string_keys_dict:\n",
    "    target_mpe = string_keys_dict[target_key]\n",
    "    print(f\"Entry with criteria {target_key}: {target_mpe}\")\n",
    "else:\n",
    "    print(f\"No entry found with criteria {target_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9951cb6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7528e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e806deb",
   "metadata": {},
   "source": [
    "# Extra Scratch Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c14e0d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant History\n",
      "{0: {0: [], 1: [], 2: [1]}, 1: {0: [], 1: [], 2: [1, 1]}, 2: {0: [], 1: [1], 2: [1, 1]}, 3: {0: [], 1: [1, 0], 2: [1, 1]}, 4: {0: [], 1: [1, 0], 2: [1, 1, 1]}, 5: {0: [1], 1: [1, 0], 2: [1, 1, 1]}, 6: {0: [1], 1: [1, 0, 0], 2: [1, 1, 1]}, 7: {0: [1], 1: [1, 0, 0], 2: [1, 1, 1, 1]}, 8: {0: [1, 0], 1: [1, 0, 0], 2: [1, 1, 1, 1]}, 9: {0: [1, 0], 1: [1, 0, 0], 2: [1, 1, 1, 1, 0]}}\n",
      "\n",
      "Bins sampled, in order\n",
      "[2, 2, 1, 1, 2, 0, 1, 2, 0, 2]\n",
      "\n",
      "Values Sampled, in order\n",
      "[1, 1, 1, 0, 1, 1, 0, 1, 0, 0]\n",
      "\n",
      "Bin Chosen\n",
      "2\n",
      "\n",
      "Reported results\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "strat_gather = Random()\n",
    "# strat_gather = EpsilonGreedy()\n",
    "# strat_gather = ThompsonSampling()\n",
    "# strat_gather = AdaptiveGatheringStrategy()\n",
    "# strat_gather = ConservativeGatheringStrategy()\n",
    "# strat_gather = WinStayLoseShift()\n",
    "\n",
    "strat_bin = MaximumDataChoosingStrategy()\n",
    "# strat_bin = MaximumSuccessChoosingStrategy()\n",
    "\n",
    "strat_report = ReportingStrategy()\n",
    "\n",
    "report_set = ReportingSetting(\"rate\")\n",
    "# report_set = ReportingSetting(\"data\")\n",
    "# report_set = ReportingSetting(\"subset\")\n",
    "\n",
    "participant = Participant(strategy_gather=strat_gather, strategy_bin=strat_bin, strategy_report=strat_report, reporting_setting=report_set)\n",
    "\n",
    "for i in range(0, num_draws):\n",
    "    participant.sample()\n",
    "    \n",
    "print('Participant History')\n",
    "print(get_full_history(participant.bin_sample_order, participant.values_sampled))\n",
    "print()\n",
    "print('Bins sampled, in order')\n",
    "print(participant.bin_sample_order)\n",
    "print()\n",
    "print('Values Sampled, in order')\n",
    "print(participant.values_sampled)\n",
    "print()\n",
    "print('Bin Chosen')\n",
    "participant.choose_bin(participant.bin_sample_order, participant.values_sampled)\n",
    "print(participant.bin_choice)\n",
    "print()\n",
    "print(\"Reported results\")\n",
    "participant.report(0)\n",
    "print(participant.reported_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8137ff12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f83c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
